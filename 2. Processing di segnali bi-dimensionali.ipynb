{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\"><h8><i>Cristina Cristalli - 838022<br>\n",
    "Francesca Franzese - 847780<br>\n",
    "    Alessia Petescia - 839141</i><br><br>\n",
    "    <b>Progetto Digital Signal and Image Management - Punto 2<br>\n",
    "        CdL Data Science 2020</b></h8></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Processing di segnali bi-dimensionali</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Riconoscere l'identità dei membri del gruppo a partire da una foto del volto.\n",
    "<br><br>Le foto dei membri del gruppo sono state scattate con <b><i> posizione, espressione e illuminazione variabile</i></b>. In totale, sono state acquisite 2050 immagini.\n",
    "Queste sono state poi ottimizzate per il task attraverso l'applicazione di un face detector implementato con OpenCV.\n",
    "<p>Il notebook è strutturato come segue:</p>\n",
    "<ol>\n",
    "<li><i>Caricamento delle immagini e applicazione del face detector</i></li><br>\n",
    "<li><i>Estrazione delle features convoluzionali attraverso modelli pre-allenati</i>: \n",
    "<ul style=\"list-style-type:square\">\n",
    "<li>VGG16</li>\n",
    "<li>Densenet121</li>\n",
    "</ul><br>\n",
    "</li>\n",
    "<li><i>Addestramento dei modelli di classificazione sulle features estratte: </i> gli iperparametri dei modelli sono stati scelti utilizzando le tecniche del Grid Search e del Random search.\n",
    "I modelli implementati sono:\n",
    "<ul style=\"list-style-type:square\">\n",
    "<li>Logistic regression</li>\n",
    "<li>Random Forest</li>\n",
    "<li>Neural Network</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Importing sklearn libraries\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "# Importing Keras libraries\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential , Model\n",
    "from tensorflow.keras.applications import VGG16, DenseNet121\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D , Input, ReLU, Softmax\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.densenet import preprocess_input as preprocess_input_ds\n",
    "from keras.engine import  Model\n",
    "from keras.layers import Input\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Face Detector</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(id_persona, train):\n",
    "    fotoscartate = 0\n",
    "    nr=0\n",
    "\n",
    "    for elem in train:\n",
    "        required_size=(224, 224)\n",
    "        pixels = cv2.imread(train[nr])\n",
    "        results = detector.detect_faces(pixels)\n",
    "\n",
    "        if not results or results[0]==False:\n",
    "            nr=nr+1\n",
    "            fotoscartate = fotoscartate + 1\n",
    "            continue\n",
    "\n",
    "        # estrazione della bounding box\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "        # estrazione della faccia\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "\n",
    "        if face.any()==[] or face.any()==False:\n",
    "            nr=nr+1\n",
    "            fotoscartate = fotoscartate + 1\n",
    "            continue\n",
    "\n",
    "        # resize dei pixels alla size standard\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        \n",
    "        # conversione dell'immagine in un array\n",
    "        face_array = asarray(image)    \n",
    "        \n",
    "        # Salvataggio delle foto in una cartella in locale, così da permettere il reload più veloce\n",
    "        directory='C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_detected'\n",
    "        os.chdir(directory)\n",
    "        cv2.imwrite(id_persona + str(nr) + '.jpg', face_array)\n",
    "\n",
    "        nr=nr+1\n",
    "\n",
    "    return fotoscartate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# foto iniziali: 675\n",
      "# foto scartate: 62\n",
      "# foto totali Alessia: 613\n"
     ]
    }
   ],
   "source": [
    "#face detector per le foto di Alessia\n",
    "alessia_train = []\n",
    "\n",
    "for elem in listdir('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_ale'):\n",
    "    alessia_train.append('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_ale/' + elem)\n",
    "\n",
    "print(\"# foto iniziali: \" + str(len(alessia_train)))\n",
    "    \n",
    "fotoscartate = face_detector(\"0_\", alessia_train)\n",
    "print(\"# foto scartate: \" + str(fotoscartate))\n",
    "\n",
    "print(\"# foto totali Alessia: \" + str(len(alessia_train) - fotoscartate) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# foto iniziali: 697\n",
      "# foto scartate: 2\n",
      "# foto totali Cristina: 695\n"
     ]
    }
   ],
   "source": [
    "#face detector per le foto di Cristina\n",
    "cristina_train = []\n",
    "\n",
    "for elem in listdir('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_cri'):\n",
    "    cristina_train.append('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_cri/' + elem)\n",
    "\n",
    "print(\"# foto iniziali: \" + str(len(cristina_train)))\n",
    "\n",
    "fotoscartate = face_detector(\"1_\", cristina_train)\n",
    "print(\"# foto scartate: \" + str(fotoscartate))\n",
    "\n",
    "print(\"# foto totali Cristina: \" + str(len(cristina_train) - fotoscartate) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# foto iniziali: 678\n",
      "# foto scartate: 11\n",
      "# foto totali Francesca: 667\n"
     ]
    }
   ],
   "source": [
    "#face detector per le foto di Francesca\n",
    "francesca_train = []\n",
    "\n",
    "for elem in listdir('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_fra'):\n",
    "    francesca_train.append('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_fra/' + elem)\n",
    "\n",
    "print(\"# foto iniziali: \" + str(len(francesca_train)))\n",
    "\n",
    "fotoscartate = face_detector(\"2_\", francesca_train)\n",
    "print(\"# foto scartate: \" + str(fotoscartate))\n",
    "\n",
    "print(\"# foto totali Francesca: \" + str(len(francesca_train) - fotoscartate) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Caricamento immagini</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caricamento immagini da locale, già passate nel face detector\n",
    "\n",
    "#carico dataset\n",
    "db_immagini = []\n",
    "# variabile \n",
    "y=[]\n",
    "\n",
    "#caricamento\n",
    "for filename in listdir('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_detected'):\n",
    "    img_data = cv2.imread('C:/Users/Francesca Franzese/Desktop/Digital Signal and Image Management/Progetto/foto_detected/' + filename)\n",
    "    img_data = cv2.resize(img_data,(224, 224))\n",
    "    img_data = np.asarray(img_data)\n",
    "    db_immagini.append([img_data])\n",
    "    y.append(list(filename)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1975"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_immagini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(db_immagini[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "db_immagini=np.array(db_immagini).reshape(-1,224, 224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(db_immagini[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classificazione</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>VGGFace</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing delle immagini per la VGG\n",
    "db_immagini_vgg = preprocess_input(db_immagini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisione in train e test\n",
    "db_immagini_vgg, y = shuffle(db_immagini_vgg, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(db_immagini_vgg, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizzo del modello VGGFace per l'estrazione delle features convoluzionali \n",
    "vgg_features = VGGFace(include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "X_train_embedding = vgg_features.predict(X_train)\n",
    "X_test_embedding = vgg_features.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Regressione Logistica</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parametri da provare in cross validation\n",
    "param_grid= [{'solver': ['newton-cg', 'lbfgs','sag', 'saga']}]\n",
    "    \n",
    "clf_lr = GridSearchCV(LogisticRegression(random_state=0), param_grid, scoring='accuracy')\n",
    "\n",
    "clf_lr.fit(X_train_embedding, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migliore combinazione di parametri:\n",
      " solver: newton-cg\n"
     ]
    }
   ],
   "source": [
    "print(\"Migliore combinazione di parametri:\")\n",
    "print(\" solver: \"+str(clf_lr.best_estimator_.solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_pred=clf_lr.predict(X_test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       188\n",
      "           1       1.00      1.00      1.00       216\n",
      "           2       1.00      0.99      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       593\n",
      "   macro avg       1.00      1.00      1.00       593\n",
      "weighted avg       1.00      1.00      1.00       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[188   0   0]\n",
      " [  0 216   0]\n",
      " [  1   0 188]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f3c538dac8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, clf_lr_pred)   \n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9983136593591906\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, clf_lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random Forest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri da provare in cross validation\n",
    "param_grid_rf = {'n_estimators': [1, 4, 8, 12, 16, 20],\n",
    "                 'criterion': ['entropy', 'gini'], }\n",
    "\n",
    "clf_rf = GridSearchCV(RandomForestClassifier(),param_grid_rf)\n",
    "\n",
    "clf_rf = clf_rf.fit(X_train_embedding, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migliore combinazione di parametri:\n",
      " n_estimators: 20\n",
      " criterion: gini\n"
     ]
    }
   ],
   "source": [
    "# Risultato della cross validation per la selezione dei parametri\n",
    "print(\"Migliore combinazione di parametri:\")\n",
    "print(\" n_estimators: \"+str(clf_rf.best_estimator_.n_estimators))\n",
    "print(\" criterion: \"+str(clf_rf.best_estimator_.criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_pred = clf_rf.predict(X_test_embedding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       188\n",
      "           1       1.00      1.00      1.00       216\n",
      "           2       1.00      0.99      1.00       189\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       593\n",
      "   macro avg       1.00      1.00      1.00       593\n",
      "weighted avg       1.00      1.00      1.00       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[188   0   0]\n",
      " [  1 215   0]\n",
      " [  1   0 188]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f3c542bbe0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, clf_rf_pred)   \n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966273187183811\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, clf_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Neural Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(optimizer='adam', activation_layer_1 ='softmax',activation_layer_2 ='softmax', activation_last_layer = 'softmax',  neurons = 1, dropout_rate_1 = 0.0, dropout_rate_2 = 0.0, dropout_rate_3 = 0.0):\n",
    "\n",
    "    modello= Sequential()\n",
    "    modello.add(Dense(neurons, activation='relu', input_shape=(512,)))\n",
    "    #modello.add(Flatten())\n",
    "    modello.add(Dropout(dropout_rate_1))\n",
    "    modello.add(Dense(neurons, activation=activation_layer_1))\n",
    "    modello.add(Dropout(dropout_rate_2))\n",
    "    modello.add(Dense(neurons, activation=activation_layer_2))\n",
    "    modello.add(Dropout(dropout_rate_3))\n",
    "    modello.add(Dense(3, activation = activation_last_layer))\n",
    "    modello.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return(modello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modello_per_grid_search = KerasClassifier(build_fn=NN_model, verbose = 0)\n",
    "batch_size = [150, 200]\n",
    "epochs = [3,5]\n",
    "optimizer = ['Adadelta', 'Adam']\n",
    "activation_layer_1 = ['softmax','relu']\n",
    "activation_layer_2 = ['softmax','relu']\n",
    "activation_last_layer = ['softmax','relu']\n",
    "neurons = [512,1024]\n",
    "dropout_rate_1 = [0.0, 0.5]\n",
    "dropout_rate_2 = [0.0, 0.5]\n",
    "dropout_rate_3 = [0.0, 0.5]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer = optimizer,\n",
    "                           dropout_rate_1 = dropout_rate_1,\n",
    "                           dropout_rate_2 = dropout_rate_2,\n",
    "                           dropout_rate_3 = dropout_rate_3,\n",
    "                           activation_layer_1=activation_layer_1, \n",
    "                           activation_layer_2=activation_layer_2,\n",
    "                           neurons = neurons,\n",
    "                           activation_last_layer = activation_last_layer)\n",
    "\n",
    "grid_search_nn = GridSearchCV(estimator=modello_per_grid_search, param_grid=param_grid, cv=2)\n",
    "network_history = grid_search_nn.fit(X_train_embedding, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_history.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network_history.predict(X_test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DenseNet121</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing delle immagini per la VGG\n",
    "db_immagini_ds = preprocess_input_ds(db_immagini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisione in train e test\n",
    "db_immagini_ds, y = shuffle(db_immagini_ds, y)\n",
    "X_train_ds, X_test_ds, y_train_ds, y_test_ds = train_test_split(db_immagini_ds, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ds = X_train_ds.astype('float32')/255.0\n",
    "X_test_ds = X_test_ds.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizzo del modello DenseNet121 per l'estrazione delle features convoluzionali\n",
    "ds_features = DenseNet121(include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "X_train_embedding_ds = ds_features.predict(X_train_ds)\n",
    "X_test_embedding_ds = ds_features.predict(X_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Regressione Logistica</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri da provare in cross validation\n",
    "param_grid= [{'solver': ['newton-cg', 'lbfgs','sag', 'saga']}]\n",
    "    \n",
    "clf_lr_ds = GridSearchCV(LogisticRegression(random_state=0), param_grid, scoring='accuracy')\n",
    "clf_lr_ds.fit(X_train_embedding_ds, y_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Migliore combinazione di parametri:\")\n",
    "print(\" solver: \"+str(clf_lr_ds.best_estimator_.solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_ds_pred=clf_lr_ds.predict(X_test_embedding_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_ds, clf_lr_ds_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_ds, clf_lr_ds_pred)   \n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test_ds, clf_lr_ds_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
